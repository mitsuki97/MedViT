{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD9uOPEK65K0",
        "outputId": "48e0f347-5072-41e2-fe73-903ab0931557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Oct 10 05:11:44 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P0             29W /   70W |     600MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Omid-Nejati/MedViT.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTsSVloNA90Y",
        "outputId": "8a56b803-f537-4d3f-e179-432ba36a1b50"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MedViT'...\n",
            "remote: Enumerating objects: 194, done.\u001b[K\n",
            "remote: Counting objects: 100% (102/102), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 194 (delta 95), reused 88 (delta 88), pack-reused 92 (from 1)\u001b[K\n",
            "Receiving objects: 100% (194/194), 819.33 KiB | 18.62 MiB/s, done.\n",
            "Resolving deltas: 100% (102/102), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/MedViT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9tJEvmBA--v",
        "outputId": "9f8d9e40-7916-4e71-9091-e434e75dc5ef"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MedViT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision.utils\n",
        "from torchvision import models\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary\n"
      ],
      "metadata": {
        "id": "lgm5vmQp8i9h"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model"
      ],
      "metadata": {
        "id": "1ta2wQYk78Mg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmPD4BBg7708",
        "outputId": "8bb9f3e3-ba80-407f-befa-f04c2906a03c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.20)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm) (0.23.0+cu126)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.35.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->timm) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->timm) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2025.8.3)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (0.8.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from MedViT import MedViT_small as tiny"
      ],
      "metadata": {
        "id": "GEQ5S3_U8E0j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "895d14e2-b8b4-409a-a32a-f7264c43df66"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "/usr/local/lib/python3.12/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tiny()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKcyvB0Y8RsK",
        "outputId": "39a7ff24-4e14-4e08-90c1-3b2b0e8785f3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.proj_head[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35YD-2Ul8aaV",
        "outputId": "0fe4602e-9ea9-4cf2-cc8b-d1751df62159"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=1024, out_features=1000, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.proj_head[0] = torch.nn.Linear(in_features=1024, out_features=2, bias=True)"
      ],
      "metadata": {
        "id": "0RE8qlwf8ZV5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.cuda()"
      ],
      "metadata": {
        "id": "dFXm96Gi8g7u"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset"
      ],
      "metadata": {
        "id": "nIefIFDW80-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install medmnist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yVawz1S84b3",
        "outputId": "94f23045-134c-4c81-86ca-5d9dc82c41fe"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting medmnist\n",
            "  Downloading medmnist-3.0.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from medmnist) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from medmnist) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from medmnist) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from medmnist) (0.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from medmnist) (4.67.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from medmnist) (11.3.0)\n",
            "Collecting fire (from medmnist)\n",
            "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from medmnist) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from medmnist) (0.23.0+cu126)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from fire->medmnist) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->medmnist) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->medmnist) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->medmnist) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (1.16.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (3.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (2025.9.30)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->medmnist) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->medmnist) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (1.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->medmnist) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->medmnist) (3.0.3)\n",
            "Downloading medmnist-3.0.2-py3-none-any.whl (25 kB)\n",
            "Downloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fire, medmnist\n",
            "Successfully installed fire-0.7.1 medmnist-3.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator"
      ],
      "metadata": {
        "id": "ChBhSTxK87hc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_flag = 'breastmnist'\n",
        "# [tissuemnist, pathmnist, chestmnist, dermamnist, octmnist,\n",
        "# pnemoniamnist, retinamnist, breastmnist, bloodmnist, tissuemnist, organamnist, organcmnist, organsmnist]\n",
        "download = True\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 10\n",
        "lr = 0.005\n",
        "\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "DataClass = getattr(medmnist, info['python_class'])"
      ],
      "metadata": {
        "id": "rH1INOxS8-iM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms.transforms import Resize\n",
        "# preprocessing\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "    torchvision.transforms.AugMix(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "\n",
        "# load the data\n",
        "train_dataset = DataClass(split='train', transform=train_transform, download=download)\n",
        "test_dataset = DataClass(split='test', transform=test_transform, download=download)\n",
        "\n",
        "# pil_dataset = DataClass(split='train', download=download)\n",
        "\n",
        "# encapsulate data into dataloader form\n",
        "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "train_loader_at_eval = data.DataLoader(dataset=train_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        "test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "TD22o8uW9L1X",
        "outputId": "fe3bc188-59c3-4773-ccfe-20af1c7192ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 560k/560k [00:00<00:00, 5.13MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset)\n",
        "print(\"===================\")\n",
        "print(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNjqCTnI9T9w",
        "outputId": "7998eaba-b73e-4057-ee07-9889f51a01e5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset BreastMNIST of size 28 (breastmnist)\n",
            "    Number of datapoints: 546\n",
            "    Root location: /root/.medmnist\n",
            "    Split: train\n",
            "    Task: binary-class\n",
            "    Number of channels: 1\n",
            "    Meaning of labels: {'0': 'malignant', '1': 'normal, benign'}\n",
            "    Number of samples: {'train': 546, 'val': 78, 'test': 156}\n",
            "    Description: The BreastMNIST is based on a dataset of 780 breast ultrasound images. It is categorized into 3 classes: normal, benign, and malignant. As we use low-resolution images, we simplify the task into binary classification by combining normal and benign as positive and classifying them against malignant as negative. We split the source dataset with a ratio of 7:1:2 into training, validation and test set. The source images of 1×500×500 are resized into 1×28×28.\n",
            "    License: CC BY 4.0\n",
            "===================\n",
            "Dataset BreastMNIST of size 28 (breastmnist)\n",
            "    Number of datapoints: 156\n",
            "    Root location: /root/.medmnist\n",
            "    Split: test\n",
            "    Task: binary-class\n",
            "    Number of channels: 1\n",
            "    Meaning of labels: {'0': 'malignant', '1': 'normal, benign'}\n",
            "    Number of samples: {'train': 546, 'val': 78, 'test': 156}\n",
            "    Description: The BreastMNIST is based on a dataset of 780 breast ultrasound images. It is categorized into 3 classes: normal, benign, and malignant. As we use low-resolution images, we simplify the task into binary classification by combining normal and benign as positive and classifying them against malignant as negative. We split the source dataset with a ratio of 7:1:2 into training, validation and test set. The source images of 1×500×500 are resized into 1×28×28.\n",
            "    License: CC BY 4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "g-ImKp2m9cLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define loss function and optimizer\n",
        "if task == \"multi-label, binary-class\":\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "else:\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
      ],
      "metadata": {
        "id": "gMy_aJrE9eeM"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    print('Epoch [%d/%d]'% (epoch+1, NUM_EPOCHS))\n",
        "    model.train()\n",
        "    for inputs, targets in tqdm(train_loader):\n",
        "        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "        # forward + backward + optimize\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        if task == 'multi-label, binary-class':\n",
        "            targets = targets.to(torch.float32)\n",
        "            loss = criterion(outputs, targets)\n",
        "        else:\n",
        "            targets = targets.squeeze().long()\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmIo3JWf9lEs",
        "outputId": "39bf3061-dba8-4c89-8153-506e0797052d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55/55 [00:24<00:00,  2.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55/55 [00:23<00:00,  2.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55/55 [00:17<00:00,  3.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55/55 [00:18<00:00,  3.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55/55 [00:17<00:00,  3.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55/55 [00:17<00:00,  3.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55/55 [00:17<00:00,  3.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55/55 [00:17<00:00,  3.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55/55 [00:17<00:00,  3.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55/55 [00:17<00:00,  3.06it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test"
      ],
      "metadata": {
        "id": "XRkfM6CM91j8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation\n",
        "\n",
        "def test(split):\n",
        "    model.eval()\n",
        "    y_true = torch.tensor([]).cuda()\n",
        "    y_score = torch.tensor([]).cuda()\n",
        "\n",
        "    data_loader = train_loader_at_eval if split == 'train' else test_loader\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in data_loader:\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            if task == 'multi-label, binary-class':\n",
        "                targets = targets.to(torch.float32)\n",
        "                outputs = outputs.softmax(dim=-1)\n",
        "            else:\n",
        "                targets = targets.squeeze().long()\n",
        "                outputs = outputs.softmax(dim=-1)\n",
        "                targets = targets.float().resize_(len(targets), 1)\n",
        "\n",
        "            y_true = torch.cat((y_true, targets), 0)\n",
        "            y_score = torch.cat((y_score, outputs), 0)\n",
        "\n",
        "        y_true = y_true.cpu().numpy()\n",
        "        y_score = y_score.detach().cpu().numpy()\n",
        "\n",
        "        evaluator = Evaluator(data_flag, split)\n",
        "        metrics = evaluator.evaluate(y_score)\n",
        "\n",
        "        print('%s  auc: %.3f  acc:%.3f' % (split, *metrics))\n",
        "\n",
        "\n",
        "print('==> Evaluating ...')\n",
        "test('train')\n",
        "test('test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCSBTpUy93r-",
        "outputId": "1c4b8174-c228-4f6f-8bc8-b34ec8de2c04"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Evaluating ...\n",
            "train  auc: 0.930  acc:0.870\n",
            "test  auc: 0.902  acc:0.853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 在原有评估代码之后添加以下内容\n",
        "\n",
        "\"\"\"## 新增：视觉-文本对齐模型（MedViT-CLIP）\"\"\"\n",
        "!pip install transformers  # 用于文本编码\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# 1. 定义视觉-文本对齐模型\n",
        "class MedViT_CLIP(nn.Module):\n",
        "    def __init__(self, vision_model, embed_dim=512):\n",
        "        super().__init__()\n",
        "        # 视觉分支（复用训练好的MedViT）\n",
        "        self.vision_model = vision_model\n",
        "        self.vision_model.proj_head = nn.Identity()  # 移除分类头，保留特征\n",
        "        self.vision_proj = nn.Linear(1024, embed_dim).cuda()  # 投影到512维\n",
        "\n",
        "        # 文本分支（使用医学BERT）\n",
        "        self.text_tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "        self.text_model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\").cuda()\n",
        "        self.text_proj = nn.Linear(768, embed_dim).cuda()  # BERT输出768维，投影到512维\n",
        "\n",
        "        # 温度系数（控制相似度尺度）\n",
        "        self.temperature = nn.Parameter(torch.tensor(0.07).cuda())\n",
        "\n",
        "    def forward_vision(self, images):\n",
        "        # 提取视觉特征并投影\n",
        "        vision_feat = self.vision_model(images)  # 1024维\n",
        "        return self.vision_proj(vision_feat)  # 512维\n",
        "\n",
        "    def forward_text(self, texts):\n",
        "        # 提取文本特征并投影\n",
        "        inputs = self.text_tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n",
        "        text_feat = self.text_model(**inputs).last_hidden_state.mean(dim=1)  # 768维\n",
        "        return self.text_proj(text_feat)  # 512维\n",
        "\n",
        "    def get_similarity(self, images, texts):\n",
        "        # 计算图像与文本的相似度\n",
        "        img_emb = self.forward_vision(images)\n",
        "        text_emb = self.forward_text(texts)\n",
        "\n",
        "        # 归一化并计算余弦相似度\n",
        "        img_emb = img_emb / img_emb.norm(dim=-1, keepdim=True)\n",
        "        text_emb = text_emb / text_emb.norm(dim=-1, keepdim=True)\n",
        "        return torch.matmul(img_emb, text_emb.T) / self.temperature\n",
        "\n",
        "\n",
        "# 2. 准备文本描述（乳腺影像类别）\n",
        "class_texts = [\n",
        "    \"Normal breast tissue: no masses, uniform echogenicity\",\n",
        "    \"Abnormal breast tissue: presence of masses, irregular shape\"\n",
        "]\n",
        "\n",
        "\n",
        "# 3. 初始化对齐模型并微调\n",
        "alignment_model = MedViT_CLIP(vision_model=model).cuda()  # 复用原有训练好的MedViT\n",
        "\n",
        "# 定义对比损失函数\n",
        "def contrastive_loss(similarity_matrix):\n",
        "    batch_size = similarity_matrix.shape[0]\n",
        "    labels = torch.arange(batch_size).cuda()  # 对角线为正样本\n",
        "    return (nn.CrossEntropyLoss()(similarity_matrix, labels) +\n",
        "            nn.CrossEntropyLoss()(similarity_matrix.T, labels)) / 2\n",
        "\n",
        "# 微调优化器（只优化投影层，保留视觉模型权重）\n",
        "optimizer = optim.AdamW([\n",
        "    {'params': alignment_model.vision_proj.parameters()},\n",
        "    {'params': alignment_model.text_proj.parameters()},\n",
        "    {'params': alignment_model.temperature}\n",
        "], lr=1e-5)\n",
        "\n",
        "\n",
        "# 4. 微调对齐模型（少量迭代，避免过拟合）\n",
        "print(\"\\n[视觉-文本对齐模型微调]\")\n",
        "alignment_model.train()\n",
        "for epoch in range(3):  # 仅微调3轮\n",
        "    total_loss = 0.0\n",
        "    for inputs, targets in tqdm(train_loader, desc=f\"微调轮次 {epoch+1}/3\"):\n",
        "        inputs = inputs.cuda()\n",
        "        targets = targets.squeeze().cpu().numpy()\n",
        "\n",
        "        # 根据标签生成对应文本（每个图像匹配其真实类别文本）\n",
        "        batch_texts = [class_texts[int(label)] for label in targets]\n",
        "\n",
        "        # 计算相似度矩阵并优化\n",
        "        similarity = alignment_model.get_similarity(inputs, batch_texts)\n",
        "        loss = contrastive_loss(similarity)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"微调轮次 {epoch+1} 平均损失: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "\n",
        "# 5. 测试视觉-文本对齐性能\n",
        "def test_alignment():\n",
        "    alignment_model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_scores = []  # 新增：用于存储每个样本的异常类得分\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in tqdm(test_loader, desc=\"测试视觉-文本对齐\"):\n",
        "            inputs = inputs.cuda()\n",
        "            targets = targets.squeeze().cpu().numpy()\n",
        "            batch_size = len(inputs)\n",
        "\n",
        "            # 计算当前批次图像与两个类别文本的相似度\n",
        "            similarity = alignment_model.get_similarity(inputs, class_texts)  # (batch_size, 2)\n",
        "\n",
        "            # 预测：取相似度更高的类别\n",
        "            preds = similarity.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "            # 收集结果\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(targets)\n",
        "            all_scores.extend(similarity[:, 1].cpu().numpy())  # 收集异常类的得分\n",
        "\n",
        "    # 计算对齐准确率和AUC\n",
        "    accuracy = sum(p == l for p, l in zip(all_preds, all_labels)) / len(all_labels)\n",
        "    auc = roc_auc_score(all_labels, all_scores)  # 使用收集的所有得分计算AUC\n",
        "\n",
        "    print(\"\\n[视觉-文本对齐模型测试结果]\")\n",
        "    print(f\"对齐准确率: {accuracy:.3f}\")\n",
        "    print(f\"对齐AUC: {auc:.3f}\")\n",
        "\n",
        "# 6. 执行对齐模型测试\n",
        "print(\"\\n==> Testing Vision-Text Alignment ...\")\n",
        "test_alignment()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4O0jOGNgdpxQ",
        "outputId": "cbe258aa-e914-4274-a6f3-0889f93472ff"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "\n",
            "[视觉-文本对齐模型微调]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "微调轮次 1/3:   0%|          | 0/55 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "微调轮次 1/3: 100%|██████████| 55/55 [00:32<00:00,  1.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "微调轮次 1 平均损失: 2.2356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "微调轮次 2/3: 100%|██████████| 55/55 [00:26<00:00,  2.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "微调轮次 2 平均损失: 2.1205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "微调轮次 3/3: 100%|██████████| 55/55 [00:25<00:00,  2.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "微调轮次 3 平均损失: 2.1124\n",
            "\n",
            "==> Testing Vision-Text Alignment ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "测试视觉-文本对齐: 100%|██████████| 8/8 [00:01<00:00,  4.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[视觉-文本对齐模型测试结果]\n",
            "对齐准确率: 0.821\n",
            "对齐AUC: 0.898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "轻量级适配模块：支持添加视觉提示（VPT）和低秩适配（LoRA） ，没做\n"
      ],
      "metadata": {
        "id": "KSYqjUwEn9Ld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"## 新增：视觉-文本对齐模型的零样本推理功能（修复DataFrame长度不匹配问题）\"\"\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def zero_shot_classification(alignment_model, unknown_loader, candidate_texts, class_names):\n",
        "    \"\"\"零样本推理核心函数\"\"\"\n",
        "    alignment_model.eval()\n",
        "    all_zero_shot_preds = []\n",
        "    all_zero_shot_scores = []\n",
        "    all_true_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in tqdm(unknown_loader, desc=\"零样本推理\"):\n",
        "            inputs = inputs.cuda()\n",
        "            true_labels = targets.squeeze().cpu().numpy()\n",
        "\n",
        "            # 计算图像与所有候选类文本的相似度\n",
        "            similarity_matrix = alignment_model.get_similarity(inputs, candidate_texts)\n",
        "            pred_indices = similarity_matrix.argmax(dim=1).cpu().numpy()\n",
        "            pred_classes = [class_names[idx] for idx in pred_indices]\n",
        "            pred_scores = similarity_matrix.max(dim=1)[0].cpu().numpy()\n",
        "\n",
        "            # 收集结果\n",
        "            all_zero_shot_preds.extend(pred_classes)\n",
        "            all_zero_shot_scores.extend(pred_scores)\n",
        "            all_true_labels.extend(true_labels)\n",
        "\n",
        "    return all_zero_shot_preds, all_zero_shot_scores, all_true_labels\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 步骤1：准备零样本推理的候选类别与文本描述\n",
        "# --------------------------\n",
        "zero_shot_class_names = [\n",
        "    \"Normal\",          # 正常乳腺组织\n",
        "    \"Abnormal\",        # 异常乳腺组织\n",
        "    \"Suspicious\"       # 新增未知类别：可疑病变\n",
        "]\n",
        "\n",
        "zero_shot_candidate_texts = [\n",
        "    \"Normal breast tissue in ultrasound: no masses or lesions, uniform echogenicity, clear boundaries between tissues\",\n",
        "    \"Abnormal breast tissue in ultrasound: presence of solid masses with irregular shape, uneven echogenicity, blurred boundaries\",\n",
        "    \"Suspicious breast tissue in ultrasound: small unclear nodules, slight echogenicity difference, need further examination\"\n",
        "]\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 步骤2：加载零样本推理数据集\n",
        "# --------------------------\n",
        "from medmnist import INFO\n",
        "data_flag = \"breastmnist\"\n",
        "info = INFO[data_flag]\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "zero_shot_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "\n",
        "zero_shot_dataset = DataClass(\n",
        "    split='test',\n",
        "    transform=zero_shot_transform,\n",
        "    download=True\n",
        ")\n",
        "zero_shot_loader = data.DataLoader(\n",
        "    zero_shot_dataset,\n",
        "    batch_size=10,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 步骤3：执行零样本推理\n",
        "# --------------------------\n",
        "print(\"\\n==> Starting Zero-Shot Classification ...\")\n",
        "pred_classes, pred_scores, true_labels = zero_shot_classification(\n",
        "    alignment_model=alignment_model,\n",
        "    unknown_loader=zero_shot_loader,\n",
        "    candidate_texts=zero_shot_candidate_texts,\n",
        "    class_names=zero_shot_class_names\n",
        ")\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 步骤4：评估零样本推理性能（返回指标）\n",
        "# --------------------------\n",
        "def evaluate_zero_shot(true_labels, pred_classes, class_names, pred_scores):\n",
        "    \"\"\"评估零样本推理性能，返回准确率和AUC\"\"\"\n",
        "    # 1. 计算有效样本准确率\n",
        "    label_mapping = {0: 0, 1: 1}  # 真实标签→候选类别索引\n",
        "    mapped_true_labels = [label_mapping.get(int(lab), -1) for lab in true_labels]\n",
        "    valid_mask = [lab != -1 for lab in mapped_true_labels]\n",
        "\n",
        "    valid_true = [mapped_true_labels[i] for i in range(len(mapped_true_labels)) if valid_mask[i]]\n",
        "    valid_pred_idx = [class_names.index(pred_classes[i]) for i in range(len(pred_classes)) if valid_mask[i]]\n",
        "    zero_shot_acc = sum(t == p for t, p in zip(valid_true, valid_pred_idx)) / len(valid_true) if valid_true else 0.0\n",
        "\n",
        "    # 2. 计算异常类识别AUC\n",
        "    abnormal_scores = []\n",
        "    binary_true = []\n",
        "    for i in range(len(pred_classes)):\n",
        "        binary_true.append(1 if int(true_labels[i]) == 1 else 0)\n",
        "        abnormal_scores.append(pred_scores[i] if class_names.index(pred_classes[i]) == 1 else 0.0)\n",
        "\n",
        "    zero_shot_auc = roc_auc_score(binary_true, abnormal_scores) if len(set(binary_true)) >= 2 else 0.0\n",
        "\n",
        "    # 打印结果\n",
        "    print(\"\\n[零样本推理性能评估]\")\n",
        "    print(f\"零样本分类准确率（有效样本）: {zero_shot_acc:.3f}\")\n",
        "    print(f\"异常类识别AUC: {zero_shot_auc:.3f}\")\n",
        "    print(f\"总推理样本数: {len(pred_classes)} | 有效评估样本数: {len(valid_true)}\")\n",
        "\n",
        "    # 打印前10个样本示例\n",
        "    print(\"\\n[前10个样本零样本推理结果示例]\")\n",
        "    print(f\"{'样本索引':<8} {'真实标签':<12} {'预测类别':<15} {'相似度得分':<12}\")\n",
        "    print(\"-\" * 50)\n",
        "    for i in range(min(10, len(pred_classes))):\n",
        "        true_label_name = \"Abnormal\" if int(true_labels[i]) == 1 else \"Normal\"\n",
        "        print(f\"{i:<8} {true_label_name:<12} {pred_classes[i]:<15} {pred_scores[i]:<12.4f}\")\n",
        "\n",
        "    return zero_shot_acc, zero_shot_auc\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 步骤5：执行评估并接收指标\n",
        "# --------------------------\n",
        "zero_shot_acc, zero_shot_auc = evaluate_zero_shot(\n",
        "    true_labels=true_labels,\n",
        "    pred_classes=pred_classes,\n",
        "    class_names=zero_shot_class_names,\n",
        "    pred_scores=pred_scores\n",
        ")\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 步骤6：修复结果保存——确保所有字段长度一致\n",
        "# --------------------------\n",
        "# 方案1：构建“样本级”结果字典（所有字段长度=样本数）\n",
        "sample_level_results = {\n",
        "    \"样本索引\": list(range(len(pred_classes))),\n",
        "    \"真实标签（数字）\": [str(lab) for lab in true_labels],\n",
        "    \"真实标签（名称）\": [\"Abnormal\" if int(lab) == 1 else \"Normal\" for lab in true_labels],\n",
        "    \"零样本预测类别\": pred_classes,\n",
        "    \"预测类别相似度得分\": [round(score, 4) for score in pred_scores]\n",
        "}\n",
        "\n",
        "# 方案2：单独保存“全局信息”（候选类别、评估指标）到文本文件\n",
        "global_info = f\"\"\"\n",
        "零样本推理全局信息\n",
        "==================\n",
        "1. 候选类别与文本描述：\n",
        "   - {zero_shot_class_names[0]}: {zero_shot_candidate_texts[0]}\n",
        "   - {zero_shot_class_names[1]}: {zero_shot_candidate_texts[1]}\n",
        "   - {zero_shot_class_names[2]}: {zero_shot_candidate_texts[2]}\n",
        "\n",
        "2. 评估指标：\n",
        "   - 零样本分类准确率（有效样本）: {zero_shot_acc:.3f}\n",
        "   - 异常类识别AUC: {zero_shot_auc:.3f}\n",
        "   - 总推理样本数: {len(pred_classes)}\n",
        "   - 数据预处理方式: Resize(224) + RGB转换 + 归一化(mean=[0.5], std=[0.5])\n",
        "\"\"\"\n",
        "\n",
        "# 分别保存两个文件，避免长度不匹配\n",
        "# 1. 保存样本级结果（CSV格式，便于查看每个样本的推理细节）\n",
        "sample_df = pd.DataFrame(sample_level_results)\n",
        "sample_df.to_csv(\"zero_shot_sample_results.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "# 2. 保存全局信息（TXT格式，记录实验配置和整体指标）\n",
        "with open(\"zero_shot_global_info.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(global_info)\n",
        "\n",
        "print(\"\\n✅ 零样本推理结果保存完成：\")\n",
        "print(\"   - 样本级细节：zero_shot_sample_results.csv\")\n",
        "print(\"   - 全局信息（配置+指标）：zero_shot_global_info.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5Dfp75Dn7bQ",
        "outputId": "a46c74b9-3fb1-4690-c76f-29cf796c824b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==> Starting Zero-Shot Classification ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "零样本推理: 100%|██████████| 16/16 [00:02<00:00,  6.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[零样本推理性能评估]\n",
            "零样本分类准确率（有效样本）: 0.737\n",
            "异常类识别AUC: 0.518\n",
            "总推理样本数: 156 | 有效评估样本数: 156\n",
            "\n",
            "[前10个样本零样本推理结果示例]\n",
            "样本索引     真实标签         预测类别            相似度得分       \n",
            "--------------------------------------------------\n",
            "0        Normal       Suspicious      -0.1920     \n",
            "1        Abnormal     Abnormal        -0.0942     \n",
            "2        Abnormal     Abnormal        0.4101      \n",
            "3        Abnormal     Abnormal        -0.0797     \n",
            "4        Abnormal     Abnormal        0.2773      \n",
            "5        Abnormal     Abnormal        0.3157      \n",
            "6        Normal       Normal          1.0121      \n",
            "7        Normal       Abnormal        0.0752      \n",
            "8        Abnormal     Abnormal        -0.3117     \n",
            "9        Abnormal     Abnormal        0.3403      \n",
            "\n",
            "✅ 零样本推理结果保存完成：\n",
            "   - 样本级细节：zero_shot_sample_results.csv\n",
            "   - 全局信息（配置+指标）：zero_shot_global_info.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"## 简化版：轻量级适配（VPT+LoRA）模块\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# --------------------------\n",
        "# 1. 简化的VPT+LoRA模块\n",
        "# --------------------------\n",
        "class VPT(nn.Module):\n",
        "    def __init__(self, embed_dim=1024):\n",
        "        super().__init__()\n",
        "        self.prompts = nn.Parameter(torch.randn(8, embed_dim).cuda() * 0.01)  # 保持8个提示\n",
        "        self.weight = nn.Parameter(torch.tensor(0.02).cuda())  # 权重从0.1降至0.02（避免特征偏移）\n",
        "        self.norm = nn.LayerNorm(embed_dim).cuda()  # 新增归一化，稳定特征分布\n",
        "\n",
        "    def forward(self, x):\n",
        "        prompts = self.prompts.mean(dim=0)\n",
        "        x = x + self.weight * prompts\n",
        "        return self.norm(x)  # 特征归一化后输出\n",
        "\n",
        "\n",
        "class LoRA(nn.Module):\n",
        "    \"\"\"低秩适配模块：用少量参数微调特征映射\"\"\"\n",
        "    def __init__(self, dim=1024, rank=4):\n",
        "        super().__init__()\n",
        "        self.A = nn.Linear(dim, rank, bias=False).cuda()  # 降维\n",
        "        self.B = nn.Linear(rank, dim, bias=False).cuda()  # 升维\n",
        "        self.weight = nn.Parameter(torch.tensor(0.02).cuda())  # LoRA权重\n",
        "        # 初始化：B矩阵置零避免初始干扰\n",
        "        nn.init.zeros_(self.B.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.weight * self.B(self.A(x))  # 残差融合\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 2. 适配后的对齐模型\n",
        "# --------------------------\n",
        "class AdaptedModel(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super().__init__()\n",
        "        self.base = base_model  # 复用原有对齐模型\n",
        "        self.vpt = VPT()        # 添加VPT模块\n",
        "        self.lora = LoRA()      # 添加LoRA模块\n",
        "\n",
        "    def forward_vision(self, images):\n",
        "        # 视觉特征流程：基础特征 → VPT → LoRA → 投影\n",
        "        feat = self.base.vision_model(images)  # 原始视觉特征\n",
        "        feat = self.vpt(feat)                  # 添加视觉提示\n",
        "        feat = self.lora(feat)                 # LoRA微调\n",
        "        return self.base.vision_proj(feat)     # 投影到512维\n",
        "\n",
        "    def get_similarity(self, images, texts):\n",
        "        # 复用文本处理和相似度计算逻辑\n",
        "        img_emb = self.forward_vision(images)\n",
        "        text_emb = self.base.forward_text(texts)\n",
        "        return torch.matmul(img_emb, text_emb.T) / self.base.temperature\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 3. 初始化与训练\n",
        "# --------------------------\n",
        "# 确保基础对齐模型已定义（关键：解决NameError）\n",
        "if 'alignment_model' not in locals():\n",
        "    # 若未定义，从基础模型重新初始化（根据实际情况调整）\n",
        "    from transformers import AutoModel, AutoTokenizer\n",
        "    class TempCLIP(nn.Module):\n",
        "        def __init__(self, vision_model):\n",
        "            super().__init__()\n",
        "            self.vision_model = vision_model\n",
        "            self.vision_model.proj_head = nn.Identity()\n",
        "            self.vision_proj = nn.Linear(1024, 512).cuda()\n",
        "            self.text_tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "            self.text_model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\").cuda()\n",
        "            self.text_proj = nn.Linear(768, 512).cuda()\n",
        "            self.temperature = nn.Parameter(torch.tensor(0.07).cuda())\n",
        "        def forward_text(self, texts):\n",
        "            inputs = self.text_tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n",
        "            return self.text_proj(self.text_model(**inputs).last_hidden_state.mean(dim=1))\n",
        "    alignment_model = TempCLIP(vision_model=model).cuda()\n",
        "\n",
        "# 初始化适配模型\n",
        "adapted_model = AdaptedModel(base_model=alignment_model).cuda()\n",
        "\n",
        "# 冻结基础模型，只训练VPT和LoRA\n",
        "for param in adapted_model.base.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in adapted_model.vpt.parameters():\n",
        "    param.requires_grad = True\n",
        "for param in adapted_model.lora.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# 训练适配模块（仅5轮，简单优化）\n",
        "optimizer = optim.Adam(adapted_model.parameters(), lr=1e-4)\n",
        "for epoch in range(5):\n",
        "    adapted_model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, targets in tqdm(train_loader, desc=f\"适配轮次 {epoch+1}/3\"):\n",
        "        inputs = inputs.cuda()\n",
        "        texts = [class_texts[int(lab)] for lab in targets.squeeze().cpu().numpy()]\n",
        "        sim = adapted_model.get_similarity(inputs, texts)\n",
        "        loss = (nn.CrossEntropyLoss()(sim, torch.arange(len(inputs)).cuda()) +\n",
        "                nn.CrossEntropyLoss()(sim.T, torch.arange(len(inputs)).cuda())) / 2\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"平均损失: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 4. 测试适配效果\n",
        "# --------------------------\n",
        "def test_model(model, loader):\n",
        "    model.eval()\n",
        "    preds, labels, scores = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in loader:\n",
        "            inputs = inputs.cuda()\n",
        "            sim = model.get_similarity(inputs, class_texts)\n",
        "            preds.extend(sim.argmax(dim=1).cpu().numpy())\n",
        "            labels.extend(targets.squeeze().cpu().numpy())\n",
        "            scores.extend(sim[:,1].cpu().numpy())\n",
        "    acc = sum(p==l for p,l in zip(preds,labels))/len(labels)\n",
        "    auc = roc_auc_score(labels, scores)\n",
        "    return acc, auc\n",
        "\n",
        "# 测试基础模型与适配模型\n",
        "base_acc, base_auc = test_model(alignment_model, test_loader)\n",
        "adapt_acc, adapt_auc = test_model(adapted_model, test_loader)\n",
        "\n",
        "print(f\"\\n基础模型 - 准确率: {base_acc:.3f}, AUC: {base_auc:.3f}\")\n",
        "print(f\"适配模型 - 准确率: {adapt_acc:.3f}, AUC: {adapt_auc:.3f}\")\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 5. 适配模型的零样本推理\n",
        "# --------------------------\n",
        "preds, scores, true = zero_shot_classification(\n",
        "    adapted_model, zero_shot_loader, zero_shot_candidate_texts, zero_shot_class_names\n",
        ")\n",
        "zero_shot_acc, zero_shot_auc = evaluate_zero_shot(true, preds, zero_shot_class_names, scores)\n",
        "print(f\"适配后零样本准确率: {zero_shot_acc:.3f}, AUC: {zero_shot_auc:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCxg-S-rD7c_",
        "outputId": "5a54d432-8145-4ec6-ddda-9dc32ea2ba92"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "适配轮次 1/3: 100%|██████████| 55/55 [00:14<00:00,  3.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "平均损失: 28.1415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "适配轮次 2/3: 100%|██████████| 55/55 [00:14<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "平均损失: 28.2892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "适配轮次 3/3: 100%|██████████| 55/55 [00:14<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "平均损失: 28.6898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "适配轮次 4/3: 100%|██████████| 55/55 [00:14<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "平均损失: 26.0294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "适配轮次 5/3: 100%|██████████| 55/55 [00:14<00:00,  3.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "平均损失: 25.2818\n",
            "\n",
            "基础模型 - 准确率: 0.750, AUC: 0.890\n",
            "适配模型 - 准确率: 0.776, AUC: 0.848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "零样本推理: 100%|██████████| 16/16 [00:02<00:00,  6.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[零样本推理性能评估]\n",
            "零样本分类准确率（有效样本）: 0.699\n",
            "异常类识别AUC: 0.364\n",
            "总推理样本数: 156 | 有效评估样本数: 156\n",
            "\n",
            "[前10个样本零样本推理结果示例]\n",
            "样本索引     真实标签         预测类别            相似度得分       \n",
            "--------------------------------------------------\n",
            "0        Normal       Suspicious      8.7619      \n",
            "1        Abnormal     Abnormal        -1.3873     \n",
            "2        Abnormal     Abnormal        9.6040      \n",
            "3        Abnormal     Suspicious      1.2823      \n",
            "4        Abnormal     Abnormal        -1.9411     \n",
            "5        Abnormal     Abnormal        -2.3570     \n",
            "6        Normal       Normal          96.0238     \n",
            "7        Normal       Normal          11.6794     \n",
            "8        Abnormal     Abnormal        -43.6004    \n",
            "9        Abnormal     Abnormal        6.5234      \n",
            "适配后零样本准确率: 0.699, AUC: 0.364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}