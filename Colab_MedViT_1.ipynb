{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD9uOPEK65K0",
        "outputId": "cf9069a0-f9d8-4817-b966-77548bdb9254"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct 28 08:35:07 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Omid-Nejati/MedViT.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTsSVloNA90Y",
        "outputId": "afe833ed-1555-4ebe-cdef-7ce4af6c25ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MedViT'...\n",
            "remote: Enumerating objects: 194, done.\u001b[K\n",
            "remote: Counting objects: 100% (102/102), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 194 (delta 95), reused 87 (delta 87), pack-reused 92 (from 1)\u001b[K\n",
            "Receiving objects: 100% (194/194), 819.25 KiB | 3.14 MiB/s, done.\n",
            "Resolving deltas: 100% (102/102), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/MedViT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9tJEvmBA--v",
        "outputId": "b5a09a3d-9482-45e2-9fed-582a8fad9ec4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MedViT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision.utils\n",
        "from torchvision import models\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary\n"
      ],
      "metadata": {
        "id": "lgm5vmQp8i9h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model"
      ],
      "metadata": {
        "id": "1ta2wQYk78Mg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmPD4BBg7708",
        "outputId": "8123ca61-3df6-4464-c753-3facc381df20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.20)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm) (0.23.0+cu126)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.35.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->timm) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->timm) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from MedViT import MedViT_small as tiny"
      ],
      "metadata": {
        "id": "GEQ5S3_U8E0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tiny()"
      ],
      "metadata": {
        "id": "JKcyvB0Y8RsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.proj_head[0]"
      ],
      "metadata": {
        "id": "35YD-2Ul8aaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.proj_head[0] = torch.nn.Linear(in_features=1024, out_features=2, bias=True)"
      ],
      "metadata": {
        "id": "0RE8qlwf8ZV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.cuda()"
      ],
      "metadata": {
        "id": "dFXm96Gi8g7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset"
      ],
      "metadata": {
        "id": "nIefIFDW80-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install medmnist"
      ],
      "metadata": {
        "id": "6yVawz1S84b3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator"
      ],
      "metadata": {
        "id": "ChBhSTxK87hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_flag = 'breastmnist'\n",
        "# [tissuemnist, pathmnist, chestmnist, dermamnist, octmnist,\n",
        "# pnemoniamnist, retinamnist, breastmnist, bloodmnist, tissuemnist, organamnist, organcmnist, organsmnist]\n",
        "download = True\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 10\n",
        "lr = 0.005\n",
        "\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "DataClass = getattr(medmnist, info['python_class'])"
      ],
      "metadata": {
        "id": "rH1INOxS8-iM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms.transforms import Resize\n",
        "# preprocessing\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "    torchvision.transforms.AugMix(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "\n",
        "# load the data\n",
        "train_dataset = DataClass(split='train', transform=train_transform, download=download)\n",
        "test_dataset = DataClass(split='test', transform=test_transform, download=download)\n",
        "\n",
        "# pil_dataset = DataClass(split='train', download=download)\n",
        "\n",
        "# encapsulate data into dataloader form\n",
        "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "train_loader_at_eval = data.DataLoader(dataset=train_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        "test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "TD22o8uW9L1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset)\n",
        "print(\"===================\")\n",
        "print(test_dataset)"
      ],
      "metadata": {
        "id": "eNjqCTnI9T9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "g-ImKp2m9cLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define loss function and optimizer\n",
        "if task == \"multi-label, binary-class\":\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "else:\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
      ],
      "metadata": {
        "id": "gMy_aJrE9eeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    print('Epoch [%d/%d]'% (epoch+1, NUM_EPOCHS))\n",
        "    model.train()\n",
        "    for inputs, targets in tqdm(train_loader):\n",
        "        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "        # forward + backward + optimize\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        if task == 'multi-label, binary-class':\n",
        "            targets = targets.to(torch.float32)\n",
        "            loss = criterion(outputs, targets)\n",
        "        else:\n",
        "            targets = targets.squeeze().long()\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "KmIo3JWf9lEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test"
      ],
      "metadata": {
        "id": "XRkfM6CM91j8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation\n",
        "\n",
        "def test(split):\n",
        "    model.eval()\n",
        "    y_true = torch.tensor([]).cuda()\n",
        "    y_score = torch.tensor([]).cuda()\n",
        "\n",
        "    data_loader = train_loader_at_eval if split == 'train' else test_loader\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in data_loader:\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            if task == 'multi-label, binary-class':\n",
        "                targets = targets.to(torch.float32)\n",
        "                outputs = outputs.softmax(dim=-1)\n",
        "            else:\n",
        "                targets = targets.squeeze().long()\n",
        "                outputs = outputs.softmax(dim=-1)\n",
        "                targets = targets.float().resize_(len(targets), 1)\n",
        "\n",
        "            y_true = torch.cat((y_true, targets), 0)\n",
        "            y_score = torch.cat((y_score, outputs), 0)\n",
        "\n",
        "        y_true = y_true.cpu().numpy()\n",
        "        y_score = y_score.detach().cpu().numpy()\n",
        "\n",
        "        evaluator = Evaluator(data_flag, split)\n",
        "        metrics = evaluator.evaluate(y_score)\n",
        "\n",
        "        print('%s  auc: %.3f  acc:%.3f' % (split, *metrics))\n",
        "\n",
        "\n",
        "print('==> Evaluating ...')\n",
        "test('train')\n",
        "test('test')"
      ],
      "metadata": {
        "id": "TCSBTpUy93r-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 在原有评估代码之后添加以下内容\n",
        "\n",
        "\"\"\"## 新增：视觉-文本对齐模型（MedViT-CLIP）\"\"\"\n",
        "!pip install transformers  # 用于文本编码\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# 1. 定义视觉-文本对齐模型\n",
        "class MedViT_CLIP(nn.Module):\n",
        "    def __init__(self, vision_model, embed_dim=512):\n",
        "        super().__init__()\n",
        "        # 视觉分支（复用训练好的MedViT）\n",
        "        self.vision_model = vision_model\n",
        "        self.vision_model.proj_head = nn.Identity()  # 移除分类头，保留特征\n",
        "        self.vision_proj = nn.Linear(1024, embed_dim).cuda()  # 投影到512维\n",
        "\n",
        "        # 文本分支（使用医学BERT）\n",
        "        self.text_tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "        self.text_model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\").cuda()\n",
        "        self.text_proj = nn.Linear(768, embed_dim).cuda()  # BERT输出768维，投影到512维\n",
        "\n",
        "        # 温度系数（控制相似度尺度）\n",
        "        self.temperature = nn.Parameter(torch.tensor(0.07).cuda())\n",
        "\n",
        "    def forward_vision(self, images):\n",
        "        # 提取视觉特征并投影\n",
        "        vision_feat = self.vision_model(images)  # 1024维\n",
        "        return self.vision_proj(vision_feat)  # 512维\n",
        "\n",
        "    def forward_text(self, texts):\n",
        "        # 提取文本特征并投影\n",
        "        inputs = self.text_tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n",
        "        text_feat = self.text_model(**inputs).last_hidden_state.mean(dim=1)  # 768维\n",
        "        return self.text_proj(text_feat)  # 512维\n",
        "\n",
        "    def get_similarity(self, images, texts):\n",
        "        # 计算图像与文本的相似度\n",
        "        img_emb = self.forward_vision(images)\n",
        "        text_emb = self.forward_text(texts)\n",
        "\n",
        "        # 归一化并计算余弦相似度\n",
        "        img_emb = img_emb / img_emb.norm(dim=-1, keepdim=True)\n",
        "        text_emb = text_emb / text_emb.norm(dim=-1, keepdim=True)\n",
        "        return torch.matmul(img_emb, text_emb.T) / self.temperature\n",
        "\n",
        "\n",
        "# 2. 准备文本描述（乳腺影像类别）\n",
        "class_texts = [\n",
        "    \"Normal breast tissue: no masses, uniform echogenicity\",\n",
        "    \"Abnormal breast tissue: presence of masses, irregular shape\"\n",
        "]\n",
        "\n",
        "\n",
        "# 3. 初始化对齐模型并微调\n",
        "alignment_model = MedViT_CLIP(vision_model=model).cuda()  # 复用原有训练好的MedViT\n",
        "\n",
        "# 定义对比损失函数\n",
        "def contrastive_loss(similarity_matrix):\n",
        "    batch_size = similarity_matrix.shape[0]\n",
        "    labels = torch.arange(batch_size).cuda()  # 对角线为正样本\n",
        "    return (nn.CrossEntropyLoss()(similarity_matrix, labels) +\n",
        "            nn.CrossEntropyLoss()(similarity_matrix.T, labels)) / 2\n",
        "\n",
        "# 微调优化器（只优化投影层，保留视觉模型权重）\n",
        "optimizer = optim.AdamW([\n",
        "    {'params': alignment_model.vision_proj.parameters()},\n",
        "    {'params': alignment_model.text_proj.parameters()},\n",
        "    {'params': alignment_model.temperature}\n",
        "], lr=1e-5)\n",
        "\n",
        "\n",
        "# 4. 微调对齐模型（少量迭代，避免过拟合）\n",
        "print(\"\\n[视觉-文本对齐模型微调]\")\n",
        "alignment_model.train()\n",
        "for epoch in range(3):  # 仅微调3轮\n",
        "    total_loss = 0.0\n",
        "    for inputs, targets in tqdm(train_loader, desc=f\"微调轮次 {epoch+1}/3\"):\n",
        "        inputs = inputs.cuda()\n",
        "        targets = targets.squeeze().cpu().numpy()\n",
        "\n",
        "        # 根据标签生成对应文本（每个图像匹配其真实类别文本）\n",
        "        batch_texts = [class_texts[int(label)] for label in targets]\n",
        "\n",
        "        # 计算相似度矩阵并优化\n",
        "        similarity = alignment_model.get_similarity(inputs, batch_texts)\n",
        "        loss = contrastive_loss(similarity)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"微调轮次 {epoch+1} 平均损失: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "\n",
        "# 5. 测试视觉-文本对齐性能\n",
        "def test_alignment():\n",
        "    alignment_model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_scores = []  # 新增：用于存储每个样本的异常类得分\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in tqdm(test_loader, desc=\"测试视觉-文本对齐\"):\n",
        "            inputs = inputs.cuda()\n",
        "            targets = targets.squeeze().cpu().numpy()\n",
        "            batch_size = len(inputs)\n",
        "\n",
        "            # 计算当前批次图像与两个类别文本的相似度\n",
        "            similarity = alignment_model.get_similarity(inputs, class_texts)  # (batch_size, 2)\n",
        "\n",
        "            # 预测：取相似度更高的类别\n",
        "            preds = similarity.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "            # 收集结果\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(targets)\n",
        "            all_scores.extend(similarity[:, 1].cpu().numpy())  # 收集异常类的得分\n",
        "\n",
        "    # 计算对齐准确率和AUC\n",
        "    accuracy = sum(p == l for p, l in zip(all_preds, all_labels)) / len(all_labels)\n",
        "    auc = roc_auc_score(all_labels, all_scores)  # 使用收集的所有得分计算AUC\n",
        "\n",
        "    print(\"\\n[视觉-文本对齐模型测试结果]\")\n",
        "    print(f\"对齐准确率: {accuracy:.3f}\")\n",
        "    print(f\"对齐AUC: {auc:.3f}\")\n",
        "\n",
        "# 6. 执行对齐模型测试\n",
        "print(\"\\n==> Testing Vision-Text Alignment ...\")\n",
        "test_alignment()\n"
      ],
      "metadata": {
        "id": "4O0jOGNgdpxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "轻量级适配模块：支持添加视觉提示（VPT）和低秩适配（LoRA） ，没做\n"
      ],
      "metadata": {
        "id": "KSYqjUwEn9Ld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"## 新增：视觉-文本对齐模型的零样本推理功能（修复DataFrame长度不匹配问题）\"\"\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def zero_shot_classification(alignment_model, unknown_loader, candidate_texts, class_names):\n",
        "    \"\"\"零样本推理核心函数\"\"\"\n",
        "    alignment_model.eval()\n",
        "    all_zero_shot_preds = []\n",
        "    all_zero_shot_scores = []\n",
        "    all_true_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in tqdm(unknown_loader, desc=\"零样本推理\"):\n",
        "            inputs = inputs.cuda()\n",
        "            true_labels = targets.squeeze().cpu().numpy()\n",
        "\n",
        "            # 计算图像与所有候选类文本的相似度\n",
        "            similarity_matrix = alignment_model.get_similarity(inputs, candidate_texts)\n",
        "            pred_indices = similarity_matrix.argmax(dim=1).cpu().numpy()\n",
        "            pred_classes = [class_names[idx] for idx in pred_indices]\n",
        "            pred_scores = similarity_matrix.max(dim=1)[0].cpu().numpy()\n",
        "\n",
        "            # 收集结果\n",
        "            all_zero_shot_preds.extend(pred_classes)\n",
        "            all_zero_shot_scores.extend(pred_scores)\n",
        "            all_true_labels.extend(true_labels)\n",
        "\n",
        "    return all_zero_shot_preds, all_zero_shot_scores, all_true_labels\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 步骤1：准备零样本推理的候选类别与文本描述\n",
        "# --------------------------\n",
        "zero_shot_class_names = [\n",
        "    \"Normal\",          # 正常乳腺组织\n",
        "    \"Abnormal\",        # 异常乳腺组织\n",
        "    \"Suspicious\"       # 新增未知类别：可疑病变\n",
        "]\n",
        "\n",
        "zero_shot_candidate_texts = [\n",
        "    \"Normal breast tissue in ultrasound: no masses or lesions, uniform echogenicity, clear boundaries between tissues\",\n",
        "    \"Abnormal breast tissue in ultrasound: presence of solid masses with irregular shape, uneven echogenicity, blurred boundaries\",\n",
        "    \"Suspicious breast tissue in ultrasound: small unclear nodules, slight echogenicity difference, need further examination\"\n",
        "]\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 步骤2：加载零样本推理数据集\n",
        "# --------------------------\n",
        "from medmnist import INFO\n",
        "data_flag = \"breastmnist\"\n",
        "info = INFO[data_flag]\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "zero_shot_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "\n",
        "zero_shot_dataset = DataClass(\n",
        "    split='test',\n",
        "    transform=zero_shot_transform,\n",
        "    download=True\n",
        ")\n",
        "zero_shot_loader = data.DataLoader(\n",
        "    zero_shot_dataset,\n",
        "    batch_size=10,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 步骤3：执行零样本推理\n",
        "# --------------------------\n",
        "print(\"\\n==> Starting Zero-Shot Classification ...\")\n",
        "pred_classes, pred_scores, true_labels = zero_shot_classification(\n",
        "    alignment_model=alignment_model,\n",
        "    unknown_loader=zero_shot_loader,\n",
        "    candidate_texts=zero_shot_candidate_texts,\n",
        "    class_names=zero_shot_class_names\n",
        ")\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 步骤4：评估零样本推理性能（返回指标）\n",
        "# --------------------------\n",
        "def evaluate_zero_shot(true_labels, pred_classes, class_names, pred_scores):\n",
        "    \"\"\"评估零样本推理性能，返回准确率和AUC\"\"\"\n",
        "    # 1. 计算有效样本准确率\n",
        "    label_mapping = {0: 0, 1: 1}  # 真实标签→候选类别索引\n",
        "    mapped_true_labels = [label_mapping.get(int(lab), -1) for lab in true_labels]\n",
        "    valid_mask = [lab != -1 for lab in mapped_true_labels]\n",
        "\n",
        "    valid_true = [mapped_true_labels[i] for i in range(len(mapped_true_labels)) if valid_mask[i]]\n",
        "    valid_pred_idx = [class_names.index(pred_classes[i]) for i in range(len(pred_classes)) if valid_mask[i]]\n",
        "    zero_shot_acc = sum(t == p for t, p in zip(valid_true, valid_pred_idx)) / len(valid_true) if valid_true else 0.0\n",
        "\n",
        "    # 2. 计算异常类识别AUC\n",
        "    abnormal_scores = []\n",
        "    binary_true = []\n",
        "    for i in range(len(pred_classes)):\n",
        "        binary_true.append(1 if int(true_labels[i]) == 1 else 0)\n",
        "        abnormal_scores.append(pred_scores[i] if class_names.index(pred_classes[i]) == 1 else 0.0)\n",
        "\n",
        "    zero_shot_auc = roc_auc_score(binary_true, abnormal_scores) if len(set(binary_true)) >= 2 else 0.0\n",
        "\n",
        "    # 打印结果\n",
        "    print(\"\\n[零样本推理性能评估]\")\n",
        "    print(f\"零样本分类准确率（有效样本）: {zero_shot_acc:.3f}\")\n",
        "    print(f\"异常类识别AUC: {zero_shot_auc:.3f}\")\n",
        "    print(f\"总推理样本数: {len(pred_classes)} | 有效评估样本数: {len(valid_true)}\")\n",
        "\n",
        "    # 打印前10个样本示例\n",
        "    print(\"\\n[前10个样本零样本推理结果示例]\")\n",
        "    print(f\"{'样本索引':<8} {'真实标签':<12} {'预测类别':<15} {'相似度得分':<12}\")\n",
        "    print(\"-\" * 50)\n",
        "    for i in range(min(10, len(pred_classes))):\n",
        "        true_label_name = \"Abnormal\" if int(true_labels[i]) == 1 else \"Normal\"\n",
        "        print(f\"{i:<8} {true_label_name:<12} {pred_classes[i]:<15} {pred_scores[i]:<12.4f}\")\n",
        "\n",
        "    return zero_shot_acc, zero_shot_auc\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 步骤5：执行评估并接收指标\n",
        "# --------------------------\n",
        "zero_shot_acc, zero_shot_auc = evaluate_zero_shot(\n",
        "    true_labels=true_labels,\n",
        "    pred_classes=pred_classes,\n",
        "    class_names=zero_shot_class_names,\n",
        "    pred_scores=pred_scores\n",
        ")\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 步骤6：修复结果保存——确保所有字段长度一致\n",
        "# --------------------------\n",
        "# 方案1：构建“样本级”结果字典（所有字段长度=样本数）\n",
        "sample_level_results = {\n",
        "    \"样本索引\": list(range(len(pred_classes))),\n",
        "    \"真实标签（数字）\": [str(lab) for lab in true_labels],\n",
        "    \"真实标签（名称）\": [\"Abnormal\" if int(lab) == 1 else \"Normal\" for lab in true_labels],\n",
        "    \"零样本预测类别\": pred_classes,\n",
        "    \"预测类别相似度得分\": [round(score, 4) for score in pred_scores]\n",
        "}\n",
        "\n",
        "# 方案2：单独保存“全局信息”（候选类别、评估指标）到文本文件\n",
        "global_info = f\"\"\"\n",
        "零样本推理全局信息\n",
        "==================\n",
        "1. 候选类别与文本描述：\n",
        "   - {zero_shot_class_names[0]}: {zero_shot_candidate_texts[0]}\n",
        "   - {zero_shot_class_names[1]}: {zero_shot_candidate_texts[1]}\n",
        "   - {zero_shot_class_names[2]}: {zero_shot_candidate_texts[2]}\n",
        "\n",
        "2. 评估指标：\n",
        "   - 零样本分类准确率（有效样本）: {zero_shot_acc:.3f}\n",
        "   - 异常类识别AUC: {zero_shot_auc:.3f}\n",
        "   - 总推理样本数: {len(pred_classes)}\n",
        "   - 数据预处理方式: Resize(224) + RGB转换 + 归一化(mean=[0.5], std=[0.5])\n",
        "\"\"\"\n",
        "\n",
        "# 分别保存两个文件，避免长度不匹配\n",
        "# 1. 保存样本级结果（CSV格式，便于查看每个样本的推理细节）\n",
        "sample_df = pd.DataFrame(sample_level_results)\n",
        "sample_df.to_csv(\"zero_shot_sample_results.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "# 2. 保存全局信息（TXT格式，记录实验配置和整体指标）\n",
        "with open(\"zero_shot_global_info.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(global_info)\n",
        "\n",
        "print(\"\\n✅ 零样本推理结果保存完成：\")\n",
        "print(\"   - 样本级细节：zero_shot_sample_results.csv\")\n",
        "print(\"   - 全局信息（配置+指标）：zero_shot_global_info.txt\")"
      ],
      "metadata": {
        "id": "f5Dfp75Dn7bQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"## 简化版：轻量级适配（VPT+LoRA）模块\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# --------------------------\n",
        "# 1. 简化的VPT+LoRA模块\n",
        "# --------------------------\n",
        "class VPT(nn.Module):\n",
        "    def __init__(self, embed_dim=1024):\n",
        "        super().__init__()\n",
        "        self.prompts = nn.Parameter(torch.randn(8, embed_dim).cuda() * 0.01)  # 保持8个提示\n",
        "        self.weight = nn.Parameter(torch.tensor(0.02).cuda())  # 权重从0.1降至0.02（避免特征偏移）\n",
        "        self.norm = nn.LayerNorm(embed_dim).cuda()  # 新增归一化，稳定特征分布\n",
        "\n",
        "    def forward(self, x):\n",
        "        prompts = self.prompts.mean(dim=0)\n",
        "        x = x + self.weight * prompts\n",
        "        return self.norm(x)  # 特征归一化后输出\n",
        "\n",
        "\n",
        "class LoRA(nn.Module):\n",
        "    \"\"\"低秩适配模块：用少量参数微调特征映射\"\"\"\n",
        "    def __init__(self, dim=1024, rank=4):\n",
        "        super().__init__()\n",
        "        self.A = nn.Linear(dim, rank, bias=False).cuda()  # 降维\n",
        "        self.B = nn.Linear(rank, dim, bias=False).cuda()  # 升维\n",
        "        self.weight = nn.Parameter(torch.tensor(0.02).cuda())  # LoRA权重\n",
        "        # 初始化：B矩阵置零避免初始干扰\n",
        "        nn.init.zeros_(self.B.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.weight * self.B(self.A(x))  # 残差融合\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 2. 适配后的对齐模型\n",
        "# --------------------------\n",
        "class AdaptedModel(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super().__init__()\n",
        "        self.base = base_model  # 复用原有对齐模型\n",
        "        self.vpt = VPT()        # 添加VPT模块\n",
        "        self.lora = LoRA()      # 添加LoRA模块\n",
        "\n",
        "    def forward_vision(self, images):\n",
        "        # 视觉特征流程：基础特征 → VPT → LoRA → 投影\n",
        "        feat = self.base.vision_model(images)  # 原始视觉特征\n",
        "        feat = self.vpt(feat)                  # 添加视觉提示\n",
        "        feat = self.lora(feat)                 # LoRA微调\n",
        "        return self.base.vision_proj(feat)     # 投影到512维\n",
        "\n",
        "    def get_similarity(self, images, texts):\n",
        "        # 复用文本处理和相似度计算逻辑\n",
        "        img_emb = self.forward_vision(images)\n",
        "        text_emb = self.base.forward_text(texts)\n",
        "        return torch.matmul(img_emb, text_emb.T) / self.base.temperature\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 3. 初始化与训练\n",
        "# --------------------------\n",
        "# 确保基础对齐模型已定义（关键：解决NameError）\n",
        "if 'alignment_model' not in locals():\n",
        "    # 若未定义，从基础模型重新初始化（根据实际情况调整）\n",
        "    from transformers import AutoModel, AutoTokenizer\n",
        "    class TempCLIP(nn.Module):\n",
        "        def __init__(self, vision_model):\n",
        "            super().__init__()\n",
        "            self.vision_model = vision_model\n",
        "            self.vision_model.proj_head = nn.Identity()\n",
        "            self.vision_proj = nn.Linear(1024, 512).cuda()\n",
        "            self.text_tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "            self.text_model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\").cuda()\n",
        "            self.text_proj = nn.Linear(768, 512).cuda()\n",
        "            self.temperature = nn.Parameter(torch.tensor(0.07).cuda())\n",
        "        def forward_text(self, texts):\n",
        "            inputs = self.text_tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n",
        "            return self.text_proj(self.text_model(**inputs).last_hidden_state.mean(dim=1))\n",
        "    alignment_model = TempCLIP(vision_model=model).cuda()\n",
        "\n",
        "# 初始化适配模型\n",
        "adapted_model = AdaptedModel(base_model=alignment_model).cuda()\n",
        "\n",
        "# 冻结基础模型，只训练VPT和LoRA\n",
        "for param in adapted_model.base.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in adapted_model.vpt.parameters():\n",
        "    param.requires_grad = True\n",
        "for param in adapted_model.lora.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# 训练适配模块（仅3轮，简单优化）\n",
        "optimizer = optim.Adam(adapted_model.parameters(), lr=1e-4)\n",
        "for epoch in range(3):\n",
        "    adapted_model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, targets in tqdm(train_loader, desc=f\"适配轮次 {epoch+1}/3\"):\n",
        "        inputs = inputs.cuda()\n",
        "        texts = [class_texts[int(lab)] for lab in targets.squeeze().cpu().numpy()]\n",
        "        sim = adapted_model.get_similarity(inputs, texts)\n",
        "        loss = (nn.CrossEntropyLoss()(sim, torch.arange(len(inputs)).cuda()) +\n",
        "                nn.CrossEntropyLoss()(sim.T, torch.arange(len(inputs)).cuda())) / 2\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"平均损失: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 4. 测试适配效果\n",
        "# --------------------------\n",
        "def test_model(model, loader):\n",
        "    model.eval()\n",
        "    preds, labels, scores = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in loader:\n",
        "            inputs = inputs.cuda()\n",
        "            sim = model.get_similarity(inputs, class_texts)\n",
        "            preds.extend(sim.argmax(dim=1).cpu().numpy())\n",
        "            labels.extend(targets.squeeze().cpu().numpy())\n",
        "            scores.extend(sim[:,1].cpu().numpy())\n",
        "    acc = sum(p==l for p,l in zip(preds,labels))/len(labels)\n",
        "    auc = roc_auc_score(labels, scores)\n",
        "    return acc, auc\n",
        "\n",
        "# 测试基础模型与适配模型\n",
        "base_acc, base_auc = test_model(alignment_model, test_loader)\n",
        "adapt_acc, adapt_auc = test_model(adapted_model, test_loader)\n",
        "\n",
        "print(f\"\\n基础模型 - 准确率: {base_acc:.3f}, AUC: {base_auc:.3f}\")\n",
        "print(f\"适配模型 - 准确率: {adapt_acc:.3f}, AUC: {adapt_auc:.3f}\")\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 5. 适配模型的零样本推理\n",
        "# --------------------------\n",
        "preds, scores, true = zero_shot_classification(\n",
        "    adapted_model, zero_shot_loader, zero_shot_candidate_texts, zero_shot_class_names\n",
        ")\n",
        "zero_shot_acc, zero_shot_auc = evaluate_zero_shot(true, preds, zero_shot_class_names, scores)\n",
        "print(f\"适配后零样本准确率: {zero_shot_acc:.3f}, AUC: {zero_shot_auc:.3f}\")\n"
      ],
      "metadata": {
        "id": "cCxg-S-rD7c_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://noto-website-2.storage.googleapis.com/pkgs/NotoSansCJKtc-hinted.zip'\n",
        "!mkdir /tmp/fonts\n",
        "!unzip -o NotoSansCJKtc-hinted.zip -d /tmp/fonts/\n",
        "!mv /tmp/fonts/NotoSansMonoCJKtc-Regular.otf /usr/share/fonts/truetype/NotoSansMonoCJKtc-Regular.otf -f\n",
        "!rm -rf /tmp/fonts\n",
        "!rm NotoSansCJKtc-hinted.zip"
      ],
      "metadata": {
        "id": "82mhmIPRpGaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 指定字體\n",
        "import matplotlib.font_manager as font_manager\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "font_dirs = ['/usr/share/fonts/truetype/']\n",
        "font_files = font_manager.findSystemFonts(fontpaths=font_dirs)\n",
        "\n",
        "for font_file in font_files:\n",
        "  font_manager.fontManager.addfont(font_file)\n",
        "\n",
        "plt.rcParams['font.family'] = \"Noto Sans Mono CJK TC\"\n"
      ],
      "metadata": {
        "id": "ZlU2ILKJpvRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"## New: JupyterBook Model Validation Visualization (Direct Plot Display)\"\"\"\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_curve, confusion_matrix, roc_auc_score\n",
        "import seaborn as sns\n",
        "\n",
        "# --------------------------\n",
        "# Precondition: Ensure the following variables are defined in previous code (reuse training/test results)\n",
        "# --------------------------\n",
        "# 1. Training loss records (extracted from adaptation training loop)\n",
        "train_losses = [29.2051, 27.8582, 28.4175]  # Average loss for adaptation epochs 1-3\n",
        "train_epochs = list(range(1, len(train_losses)+1))  # Epochs 1-3\n",
        "\n",
        "# 2. Performance metrics of base model and adapted model\n",
        "models = [\"Base Model\", \"Adapted Model\"]\n",
        "accuracies = [0.821, 0.808]  # Accuracy\n",
        "aucs = [0.898, 0.891]        # AUC values\n",
        "\n",
        "# 3. Zero-shot inference results (extracted from previous zero-shot function)\n",
        "# Assuming true_labels is defined in previous code\n",
        "true_label_names = [\"Normal\" if int(lab) == 0 else \"Abnormal\" for lab in true_labels]\n",
        "zero_shot_classes = zero_shot_class_names  # [\"Normal\", \"Suspicious\", \"Abnormal\"]\n",
        "\n",
        "# 4. Anomaly class scores (for ROC curve)\n",
        "# Assuming zero_shot_candidate_texts, alignment_model, and zero_shot_loader are defined\n",
        "abnormal_text_idx = zero_shot_candidate_texts.index([t for t in zero_shot_candidate_texts if \"Abnormal\" in t][0])\n",
        "abnormal_scores = []\n",
        "alignment_model.eval()\n",
        "with torch.no_grad():\n",
        "    for inputs, _ in zero_shot_loader:\n",
        "        inputs = inputs.cuda()\n",
        "        sim = alignment_model.get_similarity(inputs, zero_shot_candidate_texts)\n",
        "        abnormal_scores.extend(sim[:, abnormal_text_idx].cpu().numpy())\n",
        "binary_true = [1 if int(lab) == 1 else 0 for lab in true_labels]  # Binary labels for anomaly class\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# Figure 1: Training Loss Trend (direct display)\n",
        "# --------------------------\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(train_epochs, train_losses, marker='o', linewidth=2, markersize=8, color='#1f77b4')\n",
        "plt.xlabel('Adaptation Epochs', fontsize=12)\n",
        "plt.ylabel('Average Loss', fontsize=12)\n",
        "plt.title('Training Loss Trend of Adapted Model', fontsize=14, fontweight='bold')\n",
        "plt.xticks(train_epochs)  # Only display actual training epochs\n",
        "plt.grid(True, alpha=0.3)  # Light grid for better readability\n",
        "plt.tight_layout()  # Auto-adjust layout to avoid label truncation\n",
        "plt.show()  # Display directly in JupyterBook\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# Figure 2: Performance Comparison - Base Model vs Adapted Model (double bar chart)\n",
        "# --------------------------\n",
        "x = np.arange(len(models))\n",
        "width = 0.35  # Bar width to avoid overlap\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "# Plot accuracy bars\n",
        "rects1 = ax.bar(x - width/2, accuracies, width, label='Accuracy', color='#2ca02c', alpha=0.8)\n",
        "# Plot AUC bars\n",
        "rects2 = ax.bar(x + width/2, aucs, width, label='AUC', color='#ff7f0e', alpha=0.8)\n",
        "\n",
        "# Add value labels to bars (for intuitive display of specific values)\n",
        "def add_value_labels(rects):\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate(f'{height:.3f}',\n",
        "                    xy=(rect.get_x() + rect.get_width()/2, height),\n",
        "                    xytext=(0, 3),  # Vertical offset of 3 pixels to avoid overlap with bars\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "add_value_labels(rects1)\n",
        "add_value_labels(rects2)\n",
        "\n",
        "# Chart configuration\n",
        "ax.set_xlabel('Model Type', fontsize=12)\n",
        "ax.set_ylabel('Performance Metric Value', fontsize=12)\n",
        "ax.set_title('Core Performance Comparison: Base vs Adapted Model', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(models)\n",
        "ax.legend(loc='upper right')  # Place legend at upper right to avoid blocking data\n",
        "ax.grid(True, alpha=0.3, axis='y')  # Only show horizontal grid for better readability\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# Figure 3: Zero-Shot Inference Confusion Matrix (show classification details)\n",
        "# --------------------------\n",
        "# Filter valid samples (true labels only include Normal/Abnormal, exclude unmatched cases)\n",
        "valid_mask = [lab in [\"Normal\", \"Abnormal\"] for lab in true_label_names]\n",
        "valid_true = [t for t, m in zip(true_label_names, valid_mask) if m]\n",
        "valid_pred = [p for p, m in zip(pred_classes, valid_mask) if m]  # Assume pred_classes is defined\n",
        "\n",
        "# Build confusion matrix (rows: true labels, columns: predicted labels)\n",
        "cm_labels = [\"Normal\", \"Abnormal\", \"Suspicious\"]  # Predicted labels include Suspicious\n",
        "cm = confusion_matrix(valid_true, valid_pred, labels=cm_labels)\n",
        "\n",
        "# Plot confusion matrix (heatmap for intuitive display)\n",
        "plt.figure(figsize=(9, 7))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',  # annot=True shows values, fmt='d' for integers\n",
        "            xticklabels=cm_labels, yticklabels=cm_labels,\n",
        "            cbar_kws={'label': 'Number of Samples'})  # Color bar label\n",
        "plt.xlabel('Predicted Class', fontsize=12)\n",
        "plt.ylabel('True Class', fontsize=12)\n",
        "plt.title(f'Zero-Shot Inference Confusion Matrix (Valid Samples: {len(valid_true)})', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# Figure 4: Zero-Shot Anomaly Class ROC Curve (evaluate generalization ability)\n",
        "# --------------------------\n",
        "# Calculate FPR, TPR for ROC curve\n",
        "fpr, tpr, _ = roc_curve(binary_true, abnormal_scores)\n",
        "roc_auc = roc_auc_score(binary_true, abnormal_scores)  # Validate anomaly class AUC\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "# Model ROC curve (red solid line for emphasis)\n",
        "plt.plot(fpr, tpr, color='#d62728', lw=2,\n",
        "         label=f'Adapted Model Anomaly Detection (AUC = {roc_auc:.3f})')\n",
        "# Random guess baseline (gray dashed line)\n",
        "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--',\n",
        "         label='Random Guess (AUC = 0.5)')\n",
        "\n",
        "# Chart configuration\n",
        "plt.xlim([0.0, 1.0])  # X-axis range (FPR 0-1)\n",
        "plt.ylim([0.0, 1.05])  # Y-axis range (TPR 0-1.05, leaving small margin)\n",
        "plt.xlabel('False Positive Rate (FPR)', fontsize=12)\n",
        "plt.ylabel('True Positive Rate (TPR)', fontsize=12)\n",
        "plt.title('Zero-Shot Anomaly Detection ROC Curve', fontsize=14, fontweight='bold')\n",
        "plt.legend(loc='lower right')  # Place legend at lower right to avoid blocking curve\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# Additional: Summary Table of Key Metrics (display directly in JupyterBook with DataFrame)\n",
        "# --------------------------\n",
        "print(\"### Core Task Performance Summary\")\n",
        "core_df = pd.DataFrame({\n",
        "    \"Model Type\": models,\n",
        "    \"Accuracy\": accuracies,\n",
        "    \"AUC Value\": aucs,\n",
        "    \"Training Epochs\": [\"0 (Pretrained)\", \"3 Epochs\"],\n",
        "    \"Final Epoch Avg Loss\": [\"—\", f\"{train_losses[-1]:.4f}\"]\n",
        "})\n",
        "display(core_df)  # Display table in JupyterBook\n",
        "\n",
        "print(\"\\n### Zero-Shot Task Performance Summary\")\n",
        "# Assume zero_shot_acc and zero_shot_auc are defined in previous code\n",
        "zero_shot_df = pd.DataFrame({\n",
        "    \"Evaluation Metric\": [\"Zero-Shot Classification Accuracy\", \"Anomaly Detection AUC\", \"Total Inference Samples\", \"Valid Evaluation Samples\"],\n",
        "    \"Value\": [f\"{zero_shot_acc:.3f}\", f\"{zero_shot_auc:.3f}\",\n",
        "             f\"{len(pred_classes)}\", f\"{len(valid_true)}\"]\n",
        "})\n",
        "display(zero_shot_df)"
      ],
      "metadata": {
        "id": "cGs2DjfDnUpS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}